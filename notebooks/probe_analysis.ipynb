{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Probe Results Analysis\n",
    "\n",
    "This notebook replicates the functionality of `scripts/plot_probes.py` for analyzing probe performance across layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update these paths\n",
    "RESULTS_DIR = \"../results/week-34\"  # Update this path to your results directory\n",
    "TAXONOMY_FILE = \"../dataset/mcrae-x-things-taxonomy-simp.json\"  # Update this path\n",
    "SAVE_PLOTS = True  # Set to True if you want to save plots\n",
    "SAVE_DIR = \"../plots/notebook_analysis\"  # Directory to save plots\n",
    "METRICS = [\"f1\", \"accuracy\"]  # Metrics to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(results_dir):\n",
    "    \"\"\"Load all probe result files.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Look for probe result files\n",
    "    pattern = str(Path(results_dir) / \"probe_results_logistic_*.json\")\n",
    "    files = glob.glob(pattern)\n",
    "\n",
    "    for file_path in files:\n",
    "        filename = Path(file_path).name\n",
    "\n",
    "        # Extract layer from filename\n",
    "        if \"last\" in filename:\n",
    "            layer = \"last\"\n",
    "        else:\n",
    "            # Try to find number in filename\n",
    "            numbers = re.findall(r\"\\d+\", filename)\n",
    "            if numbers:\n",
    "                layer = int(numbers[-1])  # Take the last number\n",
    "            else:\n",
    "                continue  # Skip if can't find layer\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        results[layer] = data\n",
    "        print(f\"Loaded {filename} -> layer {layer}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def load_taxonomy(taxonomy_file):\n",
    "    \"\"\"Load taxonomy file.\"\"\"\n",
    "    with open(taxonomy_file, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def extract_layer_performance(results, metric=\"f1\"):\n",
    "    \"\"\"Extract performance metrics for each layer.\"\"\"\n",
    "    layer_data = []\n",
    "\n",
    "    for layer, data in results.items():\n",
    "        individual_results = data[\"individual_results\"]\n",
    "\n",
    "        # Get all scores for this metric\n",
    "        scores = [r[f\"mean_{metric}\"]*100 for r in individual_results]  # Convert to percentage\n",
    "\n",
    "        layer_data.append(\n",
    "            {\n",
    "                \"layer\": layer,\n",
    "                \"mean\": np.mean(scores),\n",
    "                \"std\": np.std(scores),\n",
    "                \"median\": np.median(scores),\n",
    "                \"min\": np.min(scores),\n",
    "                \"max\": np.max(scores),\n",
    "                \"n_attributes\": len(scores),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Sort by layer (numeric first, then 'last')\n",
    "    def sort_key(item):\n",
    "        if item[\"layer\"] == \"last\":\n",
    "            return 999\n",
    "        else:\n",
    "            return item[\"layer\"]\n",
    "\n",
    "    layer_data.sort(key=sort_key)\n",
    "    return layer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results and taxonomy\n",
    "print(f\"Loading results from: {RESULTS_DIR}\")\n",
    "results = load_results(RESULTS_DIR)\n",
    "\n",
    "if not results:\n",
    "    print(\"No results found! Please check the RESULTS_DIR path.\")\n",
    "else:\n",
    "    print(f\"Found {len(results)} layers: {sorted(results.keys())}\")\n",
    "\n",
    "# Load taxonomy\n",
    "try:\n",
    "    taxonomy = load_taxonomy(TAXONOMY_FILE)\n",
    "    print(f\"Loaded taxonomy with {len(taxonomy)} attributes\")\n",
    "    print(f\"Categories: {sorted(set(taxonomy.values()))}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load taxonomy: {e}\")\n",
    "    taxonomy = {}\n",
    "\n",
    "# Create save directory if needed\n",
    "if SAVE_PLOTS:\n",
    "    Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Plots will be saved to: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview_title",
   "metadata": {},
   "source": [
    "## 1. Overview Performance Across Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overview_performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview_performance(results, metric=\"f1\", save_path=None):\n",
    "    \"\"\"Plot line plot with mean performance at each layer.\"\"\"\n",
    "    # Extract performance data for all layers\n",
    "    layer_data = extract_layer_performance(results, metric)\n",
    "\n",
    "    if not layer_data:\n",
    "        print(\"No layer data found!\")\n",
    "        return\n",
    "\n",
    "    # Extract data for plotting\n",
    "    layers = [d[\"layer\"] for d in layer_data]\n",
    "    means = [d[\"mean\"] for d in layer_data]\n",
    "    stds = [d[\"std\"] for d in layer_data]\n",
    "    n_attributes = [d[\"n_attributes\"] for d in layer_data]\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_pos = range(len(layers))\n",
    "\n",
    "    # Main line plot\n",
    "    plt.plot(\n",
    "        x_pos,\n",
    "        means,\n",
    "        \"o-\",\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "        color=\"steelblue\",\n",
    "        label=\"Mean Performance\",\n",
    "    )\n",
    "\n",
    "    # Error bars (shaded area)\n",
    "    plt.fill_between(\n",
    "        x_pos,\n",
    "        [m - s for m, s in zip(means, stds)],\n",
    "        [m + s for m, s in zip(means, stds)],\n",
    "        alpha=0.3,\n",
    "        color=\"steelblue\",\n",
    "        label=\"± STD\",\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    plt.xlabel(\"Layer\", fontsize=12)\n",
    "    plt.ylabel(f\"Mean {metric.upper()} Score (%)\", fontsize=12)\n",
    "    plt.title(\n",
    "        f\"Probe Performance Overview - {metric.upper()} Across Layers\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Set x-axis labels\n",
    "    plt.xticks(x_pos, [str(l) for l in layers])\n",
    "\n",
    "    # Add annotations for best and worst layers\n",
    "    best_idx = np.argmax(means)\n",
    "    worst_idx = np.argmin(means)\n",
    "\n",
    "    plt.annotate(\n",
    "        f\"Best: Layer {layers[best_idx]}\\n{means[best_idx]:.1f}%\",\n",
    "        xy=(best_idx, means[best_idx]),\n",
    "        xytext=(10, 15),\n",
    "        textcoords=\"offset points\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgreen\", alpha=0.8),\n",
    "        arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0\"),\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "    plt.annotate(\n",
    "        f\"Worst: Layer {layers[worst_idx]}\\n{means[worst_idx]:.1f}%\",\n",
    "        xy=(worst_idx, means[worst_idx]),\n",
    "        xytext=(10, -25),\n",
    "        textcoords=\"offset points\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightcoral\", alpha=0.8),\n",
    "        arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0\"),\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "    # Add text box with summary stats\n",
    "    summary_text = f\"\"\"Summary:\n",
    "Layers: {len(layers)}\n",
    "Best: Layer {layers[best_idx]} ({means[best_idx]:.1f}%)\n",
    "Worst: Layer {layers[worst_idx]} ({means[worst_idx]:.1f}%)\n",
    "Range: {max(means) - min(means):.1f}%\n",
    "Avg attributes/layer: {np.mean(n_attributes):.0f}\"\"\"\n",
    "\n",
    "    plt.text(\n",
    "        0.02,\n",
    "        0.98,\n",
    "        summary_text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=9,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Saved plot to: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary to console\n",
    "    print(f\"\\nOverview Performance Summary ({metric.upper()}):\")\n",
    "    print(\"=\" * 40)\n",
    "    for i, (layer, mean, std, n_attr) in enumerate(\n",
    "        zip(layers, means, stds, n_attributes)\n",
    "    ):\n",
    "        status = \"\"\n",
    "        if i == best_idx:\n",
    "            status = \" ⭐ BEST\"\n",
    "        elif i == worst_idx:\n",
    "            status = \" ⚠️  WORST\"\n",
    "        print(f\"Layer {layer:>4}: {mean:.1f}% ± {std:.1f}% (n={n_attr:3d}){status}\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nPerformance range: {min(means):.1f}% - {max(means):.1f}% (Δ={max(means)-min(means):.1f}%)\"\n",
    "    )\n",
    "\n",
    "    return layer_data\n",
    "\n",
    "\n",
    "# Create overview performance plot\n",
    "for metric in METRICS:\n",
    "    save_path = f\"{SAVE_DIR}/overview_performance_{metric}.png\" if SAVE_PLOTS else None\n",
    "    layer_data = overview_performance(results, metric=metric, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "category_title",
   "metadata": {},
   "source": [
    "## 2. Category Breakdown Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "category_breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_breakdown(results, layer, taxonomy, metric=\"f1\", save_path=None):\n",
    "    \"\"\"Plot performance by semantic category.\"\"\"\n",
    "    if layer not in results:\n",
    "        print(f\"Layer {layer} not found in results\")\n",
    "        return\n",
    "\n",
    "    # Get all attribute scores for this layer\n",
    "    individual_results = results[layer][\"individual_results\"]\n",
    "\n",
    "    # Group scores and baselines by category\n",
    "    category_scores = {}\n",
    "    category_baselines = {}\n",
    "    category_counts = {}\n",
    "    for result in individual_results:\n",
    "        attr = result[\"attribute\"]\n",
    "        score = result[f\"mean_{metric}\"] * 100  # Convert to percentage\n",
    "        baseline = result[f\"baseline_mean_{metric}\"] * 100\n",
    "        # Get category from taxonomy\n",
    "        category = taxonomy.get(attr, \"unknown\")\n",
    "        if category not in category_scores:\n",
    "            category_scores[category] = []\n",
    "            category_baselines[category] = []\n",
    "            category_counts[category] = 0\n",
    "        category_scores[category].append(score)\n",
    "        category_baselines[category].append(baseline)\n",
    "        category_counts[category] += 1\n",
    "        \n",
    "    # Calculate mean score and baseline per category\n",
    "    category_means = {}\n",
    "    category_stds = {}\n",
    "    category_baseline_means = {}\n",
    "    for cat, scores in category_scores.items():\n",
    "        category_means[cat] = np.mean(scores)\n",
    "        category_stds[cat] = np.std(scores)\n",
    "        category_baseline_means[cat] = np.mean(category_baselines[cat])\n",
    "        \n",
    "    # Sort categories by performance\n",
    "    sorted_categories = sorted(category_means.items(), key=lambda x: x[1], reverse=True)\n",
    "    categories = [cat for cat, _ in sorted_categories]\n",
    "    means = [score for _, score in sorted_categories]\n",
    "    stds = [category_stds[cat] for cat, _ in sorted_categories]\n",
    "    counts = [category_counts[cat] for cat, _ in sorted_categories]\n",
    "    baselines = [category_baseline_means[cat] for cat, _ in sorted_categories]\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(categories)))\n",
    "    x_pos = range(len(categories))\n",
    "\n",
    "    bars = plt.bar(\n",
    "        x_pos, means, yerr=stds, capsize=5, color=colors, alpha=0.7, edgecolor=\"black\"\n",
    "    )\n",
    "\n",
    "    # Add red baseline markers for each category\n",
    "    for i, baseline in enumerate(baselines):\n",
    "        plt.plot(\n",
    "            [i - 0.4, i + 0.4],\n",
    "            [baseline, baseline],\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=2,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Add baseline percentage text\n",
    "        plt.text(\n",
    "            i,\n",
    "            baseline - 2,\n",
    "            f\"{baseline:.1f}%\",\n",
    "            color=\"red\",\n",
    "            fontweight=\"bold\",\n",
    "            ha=\"center\",\n",
    "            va=\"top\",\n",
    "            fontsize=8,\n",
    "            bbox=dict(\n",
    "                boxstyle=\"round,pad=0.2\", facecolor=\"white\", edgecolor=\"red\", alpha=0.8\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(f\"Mean {metric.upper()} Score (%)\")\n",
    "    plt.title(f\"{metric.upper()} Performance by Category - Layer {layer}\")\n",
    "    plt.xticks(x_pos, categories, rotation=45, ha=\"right\")\n",
    "    plt.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    # Add performance value and count labels on bars\n",
    "    for i, (bar, count, mean_val) in enumerate(zip(bars, counts, means)):\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + stds[i] + 1,\n",
    "            f\"{mean_val:.1f}%\\nn={count}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Saved plot to: {save_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed breakdown\n",
    "    print(f\"\\nCategory Breakdown for Layer {layer}:\")\n",
    "    print(\"=\" * 50)\n",
    "    for cat, mean_score in sorted_categories:\n",
    "        std_score = category_stds[cat]\n",
    "        baseline_score = category_baseline_means[cat]\n",
    "        count = category_counts[cat]\n",
    "        print(\n",
    "            f\"{cat:15s}: {mean_score:.1f}% ± {std_score:.1f}% (baseline: {baseline_score:.1f}%, n={count})\"\n",
    "        )\n",
    "        \n",
    "    return category_means, category_counts\n",
    "\n",
    "\n",
    "# Create category breakdown for best and last layers\n",
    "if taxonomy and results:\n",
    "    # Find best layer\n",
    "    layer_data = extract_layer_performance(results, \"f1\")\n",
    "    if layer_data:\n",
    "        best_idx = max(range(len(layer_data)), key=lambda i: layer_data[i]['mean'])\n",
    "        best_layer = layer_data[best_idx]['layer']\n",
    "        print(f\"Best performing layer: {best_layer} (F1: {layer_data[best_idx]['mean']:.1f}%)\")\n",
    "        \n",
    "        # Plot for best layer\n",
    "        save_path = f\"{SAVE_DIR}/category_breakdown_best.png\" if SAVE_PLOTS else None\n",
    "        category_breakdown(results, best_layer, taxonomy, save_path=save_path)\n",
    "        \n",
    "        # Plot for last layer if different from best\n",
    "        if \"last\" in results and best_layer != \"last\":\n",
    "            save_path = f\"{SAVE_DIR}/category_breakdown_last.png\" if SAVE_PLOTS else None\n",
    "            category_breakdown(results, \"last\", taxonomy, save_path=save_path)\n",
    "else:\n",
    "    print(\"Skipping category analysis - no taxonomy or results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance_curves_title",
   "metadata": {},
   "source": [
    "## 3. Performance Curves by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance_curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_curves(results, taxonomy, categories=None, metric=\"f1\", save_path=None):\n",
    "    \"\"\"Plot performance curves by category across layers.\"\"\"\n",
    "    if not categories:\n",
    "        # Get all unique categories from taxonomy\n",
    "        categories = list(set(taxonomy.values()))\n",
    "        categories.sort()\n",
    "\n",
    "    # Initialize data structure for each category\n",
    "    category_data = {cat: [] for cat in categories}\n",
    "\n",
    "    # Sort layers properly\n",
    "    sorted_layers = sorted(results.keys(), key=lambda x: 999 if x == \"last\" else x)\n",
    "\n",
    "    # For each layer, calculate performance by category\n",
    "    for layer in sorted_layers:\n",
    "        if layer not in results:\n",
    "            continue\n",
    "\n",
    "        individual_results = results[layer][\"individual_results\"]\n",
    "\n",
    "        # Group scores by category for this layer\n",
    "        layer_category_scores = {cat: [] for cat in categories}\n",
    "\n",
    "        for result in individual_results:\n",
    "            attr = result[\"attribute\"]\n",
    "            score = result[f\"mean_{metric}\"] * 100  # Convert to percentage\n",
    "            category = taxonomy.get(attr, \"unknown\")\n",
    "\n",
    "            if category in layer_category_scores:\n",
    "                layer_category_scores[category].append(score)\n",
    "\n",
    "        # Calculate mean for each category in this layer\n",
    "        for cat in categories:\n",
    "            if layer_category_scores[cat]:  # If category has attributes in this layer\n",
    "                mean_score = np.mean(layer_category_scores[cat])\n",
    "                std_score = np.std(layer_category_scores[cat])\n",
    "                n_attrs = len(layer_category_scores[cat])\n",
    "\n",
    "                category_data[cat].append(\n",
    "                    {\n",
    "                        \"layer\": layer,\n",
    "                        \"mean\": mean_score,\n",
    "                        \"std\": std_score,\n",
    "                        \"n_attributes\": n_attrs,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # Filter categories that have data across layers\n",
    "    categories_with_data = []\n",
    "    for cat in categories:\n",
    "        if len(category_data[cat]) >= 3:  # At least 3 layers with data\n",
    "            categories_with_data.append(cat)\n",
    "\n",
    "    if not categories_with_data:\n",
    "        print(\"No categories with sufficient data across layers!\")\n",
    "        return\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Color palette\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(categories_with_data)))\n",
    "\n",
    "    # Plot each category\n",
    "    for i, cat in enumerate(categories_with_data):\n",
    "        data = category_data[cat]\n",
    "        layers = [d[\"layer\"] for d in data]\n",
    "        means = [d[\"mean\"] for d in data]\n",
    "        stds = [d[\"std\"] for d in data]\n",
    "\n",
    "        # Convert layer names to x positions\n",
    "        x_positions = []\n",
    "        for layer in layers:\n",
    "            if layer == \"last\":\n",
    "                x_positions.append(len(sorted_layers) - 1)\n",
    "            else:\n",
    "                x_positions.append(sorted_layers.index(layer))\n",
    "\n",
    "        # Plot line with error bars\n",
    "        plt.plot(\n",
    "            x_positions,\n",
    "            means,\n",
    "            \"o-\",\n",
    "            linewidth=2.5,\n",
    "            markersize=6,\n",
    "            color=colors[i],\n",
    "            label=f\"{cat}\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Add error bars (shaded area)\n",
    "        plt.fill_between(\n",
    "            x_positions,\n",
    "            [m - s for m, s in zip(means, stds)],\n",
    "            [m + s for m, s in zip(means, stds)],\n",
    "            alpha=0.15,\n",
    "            color=colors[i],\n",
    "        )\n",
    "\n",
    "    # Formatting\n",
    "    plt.xlabel(\"Layer\", fontsize=12)\n",
    "    plt.ylabel(f\"Mean {metric.upper()} Score (%)\", fontsize=12)\n",
    "    plt.title(\n",
    "        f\"Performance Curves by Category - {metric.upper()} Across Layers\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Set x-axis\n",
    "    x_labels = [str(layer) for layer in sorted_layers]\n",
    "    plt.xticks(range(len(sorted_layers)), x_labels)\n",
    "\n",
    "    # Legend\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Saved plot to: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Print analysis\n",
    "    print(f\"\\nPerformance Curves Analysis ({metric.upper()}):\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Find peak layer for each category\n",
    "    category_peaks = {}\n",
    "    for cat in categories_with_data:\n",
    "        data = category_data[cat]\n",
    "        if data:\n",
    "            best_performance = max(data, key=lambda x: x[\"mean\"])\n",
    "            category_peaks[cat] = {\n",
    "                \"layer\": best_performance[\"layer\"],\n",
    "                \"score\": best_performance[\"mean\"],\n",
    "                \"n_attrs\": best_performance[\"n_attributes\"],\n",
    "            }\n",
    "\n",
    "    # Sort categories by their peak performance layer\n",
    "    sorted_peaks = sorted(\n",
    "        category_peaks.items(),\n",
    "        key=lambda x: 999 if x[1][\"layer\"] == \"last\" else x[1][\"layer\"],\n",
    "    )\n",
    "\n",
    "    print(\"Categories ranked by peak performance layer:\")\n",
    "    for cat, peak_info in sorted_peaks:\n",
    "        print(\n",
    "            f\"  {cat:15s}: Peak at layer {peak_info['layer']:>4} \"\n",
    "            f\"({peak_info['score']:.1f}%, n={peak_info['n_attrs']})\"\n",
    "        )\n",
    "\n",
    "    return category_data, category_peaks\n",
    "\n",
    "\n",
    "# Create performance curves plot\n",
    "if taxonomy and results:\n",
    "    save_path = f\"{SAVE_DIR}/performance_curves.png\" if SAVE_PLOTS else None\n",
    "    category_data, category_peaks = performance_curves(results, taxonomy, save_path=save_path)\n",
    "else:\n",
    "    print(\"Skipping performance curves - no taxonomy or results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attribute_title",
   "metadata": {},
   "source": [
    "## 4. Individual Attribute Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attribute_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_breakdown(results, layer, taxonomy, metric=\"f1\", save_path=None, top_n_per_category=10):\n",
    "    \"\"\"Plot individual attributes as bars, color-coded by category.\"\"\"\n",
    "    if layer not in results:\n",
    "        print(f\"Layer {layer} not found in results\")\n",
    "        return\n",
    "\n",
    "    # Get all attribute scores for this layer\n",
    "    individual_results = results[layer][\"individual_results\"]\n",
    "\n",
    "    # Create list of (attribute, score, baseline, category) tuples\n",
    "    attr_data = []\n",
    "    for result in individual_results:\n",
    "        attr = result[\"attribute\"]\n",
    "        score = result[f\"mean_{metric}\"] * 100  # Convert to percentage\n",
    "        baseline = result[f\"baseline_mean_{metric}\"] * 100\n",
    "        category = taxonomy.get(attr, \"unknown\")\n",
    "        attr_data.append((attr, score, baseline, category))\n",
    "\n",
    "    # Group by category and sort within each category by score descending\n",
    "    category_groups = {}\n",
    "    for attr, score, baseline, category in attr_data:\n",
    "        if category not in category_groups:\n",
    "            category_groups[category] = []\n",
    "        category_groups[category].append((attr, score, baseline))\n",
    "\n",
    "    # Sort categories by their mean performance\n",
    "    category_means = {\n",
    "        cat: np.mean([score for _, score, _ in attrs])\n",
    "        for cat, attrs in category_groups.items()\n",
    "    }\n",
    "    sorted_categories = sorted(category_means.items(), key=lambda x: x[1], reverse=True)\n",
    "    category_order = [cat for cat, _ in sorted_categories]\n",
    "\n",
    "    # Sort attributes within each category by score\n",
    "    for cat in category_groups:\n",
    "        category_groups[cat].sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get unique categories and assign colors\n",
    "    unique_categories = category_order\n",
    "    category_colors = dict(\n",
    "        zip(unique_categories, plt.cm.Set3(np.linspace(0, 1, len(unique_categories))))\n",
    "    )\n",
    "\n",
    "    # Create plot for top N per category\n",
    "    category_groups_top = {}\n",
    "    for cat in category_order:\n",
    "        if cat in category_groups:\n",
    "            category_groups_top[cat] = category_groups[cat][:top_n_per_category]\n",
    "\n",
    "    # Flatten data for plotting\n",
    "    attributes = []\n",
    "    scores = []\n",
    "    baselines = []\n",
    "    categories = []\n",
    "    \n",
    "    for cat in category_order:\n",
    "        if cat in category_groups_top:\n",
    "            for attr, score, baseline in category_groups_top[cat]:\n",
    "                attributes.append(attr)\n",
    "                scores.append(score)\n",
    "                baselines.append(baseline)\n",
    "                categories.append(cat)\n",
    "\n",
    "    if not attributes:\n",
    "        print(\"No attributes to plot\")\n",
    "        return\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    x_pos = range(len(attributes))\n",
    "    bar_colors = [category_colors[cat] for cat in categories]\n",
    "\n",
    "    # Create bars\n",
    "    bars = plt.bar(\n",
    "        x_pos,\n",
    "        scores,\n",
    "        color=bar_colors,\n",
    "        alpha=0.7,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    # Add baseline markers\n",
    "    for i, baseline in enumerate(baselines):\n",
    "        plt.plot(\n",
    "            [i - 0.4, i + 0.4],\n",
    "            [baseline, baseline],\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "    # Add category separators and labels\n",
    "    current_cat = None\n",
    "    cat_positions = {}\n",
    "    \n",
    "    for i, cat in enumerate(categories):\n",
    "        if cat not in cat_positions:\n",
    "            cat_positions[cat] = []\n",
    "        cat_positions[cat].append(i)\n",
    "        \n",
    "        if current_cat is not None and cat != current_cat:\n",
    "            plt.axvline(x=i-0.5, color=\"gray\", linestyle=\"-\", linewidth=2, alpha=0.6)\n",
    "        current_cat = cat\n",
    "\n",
    "    # Add category labels at the top\n",
    "    y_max = max(scores) * 1.1\n",
    "    for cat, positions in cat_positions.items():\n",
    "        center_pos = (min(positions) + max(positions)) / 2\n",
    "        plt.text(\n",
    "            center_pos,\n",
    "            y_max * 0.95,\n",
    "            cat,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=12,\n",
    "            bbox=dict(\n",
    "                boxstyle=\"round,pad=0.3\",\n",
    "                facecolor=category_colors[cat],\n",
    "                alpha=0.3,\n",
    "                edgecolor=\"black\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # Formatting\n",
    "    plt.xlabel(\"Attributes (grouped by category)\", fontsize=12)\n",
    "    plt.ylabel(f\"{metric.upper()} Score (%)\", fontsize=12)\n",
    "    plt.title(\n",
    "        f\"Top {top_n_per_category} Attributes per Category (Layer {layer})\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    plt.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    # Set x-axis labels\n",
    "    plt.xticks(x_pos, attributes, rotation=90, ha=\"right\", fontsize=8)\n",
    "    plt.ylim(0, y_max)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Saved plot to: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Print top attributes per category\n",
    "    print(f\"\\nTop {top_n_per_category} attributes per category (Layer {layer}):\")\n",
    "    for cat in category_order:\n",
    "        if cat in category_groups_top and category_groups_top[cat]:\n",
    "            print(f\"\\n{cat}:\")\n",
    "            for i, (attr, score, baseline) in enumerate(category_groups_top[cat], 1):\n",
    "                print(f\"  {i:2d}. {attr:<30}: {score:.1f}% (baseline: {baseline:.1f}%)\")\n",
    "\n",
    "    return attr_data\n",
    "\n",
    "\n",
    "# Create attribute breakdown for best layer\n",
    "if taxonomy and results and 'best_layer' in locals():\n",
    "    save_path = f\"{SAVE_DIR}/attribute_breakdown_best.png\" if SAVE_PLOTS else None\n",
    "    attribute_breakdown(results, best_layer, taxonomy, save_path=save_path)\n",
    "else:\n",
    "    print(\"Skipping attribute breakdown - no taxonomy, results, or best layer identified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_title",
   "metadata": {},
   "source": [
    "## 5. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "if results:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROBE ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_layers = len(results)\n",
    "    layer_data = extract_layer_performance(results, \"f1\")\n",
    "    \n",
    "    if layer_data:\n",
    "        best_layer_data = max(layer_data, key=lambda x: x['mean'])\n",
    "        worst_layer_data = min(layer_data, key=lambda x: x['mean'])\n",
    "        avg_performance = np.mean([d['mean'] for d in layer_data])\n",
    "        \n",
    "        print(f\"\\nDataset Overview:\")\n",
    "        print(f\"- Total layers analyzed: {total_layers}\")\n",
    "        print(f\"- Average attributes per layer: {np.mean([d['n_attributes'] for d in layer_data]):.0f}\")\n",
    "        print(f\"- Performance range: {worst_layer_data['mean']:.1f}% - {best_layer_data['mean']:.1f}%\")\n",
    "        print(f\"- Average performance: {avg_performance:.1f}%\")\n",
    "        \n",
    "        print(f\"\\nKey Findings:\")\n",
    "        print(f\"- Best performing layer: {best_layer_data['layer']} ({best_layer_data['mean']:.1f}% F1)\")\n",
    "        print(f\"- Worst performing layer: {worst_layer_data['layer']} ({worst_layer_data['mean']:.1f}% F1)\")\n",
    "        print(f\"- Performance improvement: {best_layer_data['mean'] - worst_layer_data['mean']:.1f}% from worst to best\")\n",
    "        \n",
    "        if taxonomy:\n",
    "            print(f\"\\nCategory Analysis:\")\n",
    "            print(f\"- Total categories: {len(set(taxonomy.values()))}\")\n",
    "            print(f\"- Categories: {', '.join(sorted(set(taxonomy.values())))}\")\n",
    "            \n",
    "            if 'category_peaks' in locals():\n",
    "                print(f\"\\nCategory Peak Performance:\")\n",
    "                for cat, peak in sorted(category_peaks.items(), key=lambda x: x[1]['score'], reverse=True):\n",
    "                    print(f\"- {cat}: {peak['score']:.1f}% at layer {peak['layer']}\")\n",
    "    \n",
    "    print(f\"\\nRecommendations:\")\n",
    "    if 'best_layer_data' in locals():\n",
    "        print(f\"- Use layer {best_layer_data['layer']} for optimal probe performance\")\n",
    "        print(f\"- Consider layers around {best_layer_data['layer']} for fine-tuning\")\n",
    "        \n",
    "    if SAVE_PLOTS:\n",
    "        print(f\"\\nAll plots saved to: {SAVE_DIR}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nNo results to summarize. Please check your RESULTS_DIR configuration.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}