{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Up VLMs Dataset Browser\n",
    "\n",
    "This notebook helps browse and understand the Kamatha \"What's Up\" dataset with multiple subsets:\n",
    "- Visual Genome Q&A (one/two objects)\n",
    "- COCO Q&A (one/two objects) \n",
    "- Controlled images\n",
    "- Controlled CLEVR\n",
    "\n",
    "## Dataset Format\n",
    "\n",
    "**Important:** Datasets come in two formats:\n",
    "\n",
    "**Format 1 - List** (VG, COCO):\n",
    "```python\n",
    "[image_id, correct_caption, incorrect_caption, ...]\n",
    "```\n",
    "\n",
    "**Format 2 - Dictionary** (Controlled images, Controlled CLEVR):\n",
    "```python\n",
    "{\n",
    "    'image_path': 'path/to/image.jpg',\n",
    "    'caption_options': [correct_caption, incorrect_caption, ...]\n",
    "}\n",
    "```\n",
    "\n",
    "In both cases:\n",
    "- **First caption option is always CORRECT**\n",
    "- **Remaining caption options are INCORRECT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from collections import Counter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path on cluster\n",
    "BASE_PATH = Path(\"/leonardo_work/EUHPC_D27_102/compmech/whatsup_vlms_data/\")\n",
    "\n",
    "# Dataset configurations\n",
    "DATASETS = {\n",
    "    'vg_two_obj': {\n",
    "        'json': BASE_PATH / 'vg_qa_two_obj.json',\n",
    "        'images': BASE_PATH / 'vg_images',\n",
    "        'description': 'Visual Genome - Two objects (left/right)'\n",
    "    },\n",
    "    'vg_one_obj': {\n",
    "        'json': BASE_PATH / 'vg_qa_one_obj.json',\n",
    "        'images': BASE_PATH / 'vg_images',\n",
    "        'description': 'Visual Genome - One object (left/right)'\n",
    "    },\n",
    "    'controlled_images': {\n",
    "        'json': BASE_PATH / 'controlled_images_dataset.json',\n",
    "        'images': BASE_PATH / 'controlled_images',\n",
    "        'description': 'Controlled images - Two objects (left/right/up/down)'\n",
    "    },\n",
    "    'coco_two_obj': {\n",
    "        'json': BASE_PATH / 'coco_qa_two_obj.json',\n",
    "        'images': BASE_PATH / 'val2017',\n",
    "        'description': 'COCO - Two objects (up/down/left/right)'\n",
    "    },\n",
    "    'coco_one_obj': {\n",
    "        'json': BASE_PATH / 'coco_qa_one_obj.json',\n",
    "        'images': BASE_PATH / 'val2017',\n",
    "        'description': 'COCO - One object (up/down/left/right)'\n",
    "    },\n",
    "    'controlled_clevr': {\n",
    "        'json': BASE_PATH / 'controlled_clevr_dataset.json',\n",
    "        'images': BASE_PATH / 'controlled_clevr',\n",
    "        'description': 'Controlled CLEVR (front/behind/left/right)'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_key):\n",
    "    \"\"\"Load a specific dataset\n",
    "\n",
    "    Dataset formats:\n",
    "    1. List format: [image_id, correct_caption, incorrect_caption, ...]\n",
    "    2. Dict format: {'image_path': '...', 'caption_options': [correct, incorrect, ...]}\n",
    "    \n",
    "    First caption option is always CORRECT in both formats\n",
    "    \"\"\"\n",
    "    config = DATASETS[dataset_key]\n",
    "    with open(config['json'], 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data, config\n",
    "\n",
    "def is_dict_format(item):\n",
    "    \"\"\"Check if dataset item is in dictionary format\"\"\"\n",
    "    return isinstance(item, dict) and 'caption_options' in item\n",
    "\n",
    "def get_image_id(item):\n",
    "    \"\"\"Extract image ID from either format\"\"\"\n",
    "    if is_dict_format(item):\n",
    "        return item['image_path']\n",
    "    else:\n",
    "        return item[0]\n",
    "\n",
    "def get_correct_caption(item):\n",
    "    \"\"\"Extract correct caption (always first) from either format\"\"\"\n",
    "    if is_dict_format(item):\n",
    "        return item['caption_options'][0]\n",
    "    else:\n",
    "        return item[1]\n",
    "\n",
    "def get_incorrect_captions(item):\n",
    "    \"\"\"Extract incorrect captions from either format\"\"\"\n",
    "    if is_dict_format(item):\n",
    "        return item['caption_options'][1:]\n",
    "    else:\n",
    "        return [item[2]] if len(item) > 2 else []\n",
    "\n",
    "def get_image_path(config, image_id, dataset_key):\n",
    "    \"\"\"Get full path to image based on dataset conventions\"\"\"\n",
    "    # For dict format, image_id is already a relative path\n",
    "    if isinstance(image_id, str) and ('/' in image_id or image_id.endswith('.jpg') or image_id.endswith('.jpeg')):\n",
    "        # It's already a path, might need to adjust\n",
    "        if image_id.startswith('data/'):\n",
    "            # Remove 'data/' prefix and use BASE_PATH\n",
    "            return BASE_PATH / image_id.replace('data/', '')\n",
    "        return config['images'] / Path(image_id).name\n",
    "    \n",
    "    # For list format with numeric IDs\n",
    "    if 'coco' in dataset_key:\n",
    "        # COCO uses zero-padded 12-digit IDs\n",
    "        filename = f\"{str(image_id).zfill(12)}.jpg\"\n",
    "    else:\n",
    "        # Other datasets may use different conventions\n",
    "        filename = f\"{image_id}.jpg\" if not str(image_id).endswith('.jpg') else image_id\n",
    "    return config['images'] / filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(data, dataset_key):\n",
    "    \"\"\"Analyze and print dataset statistics\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Dataset: {DATASETS[dataset_key]['description']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Total samples\n",
    "    print(f\"\\nTotal samples: {len(data)}\")\n",
    "    \n",
    "    # Detect format\n",
    "    if data:\n",
    "        if is_dict_format(data[0]):\n",
    "            print(f\"\\nData format: Dictionary\")\n",
    "            print(f\"Keys: {list(data[0].keys())}\")\n",
    "            print(f\"\\nFirst example:\")\n",
    "            example = data[0]\n",
    "            print(f\"  Image path: {example['image_path']}\")\n",
    "            print(f\"  Number of caption options: {len(example['caption_options'])}\")\n",
    "            print(f\"  Correct caption: {example['caption_options'][0]}\")\n",
    "            print(f\"  Incorrect captions: {example['caption_options'][1:]}\")\n",
    "        else:\n",
    "            print(f\"\\nData format: List\")\n",
    "            print(f\"Number of fields per item: {len(data[0])}\")\n",
    "            print(f\"\\nFirst example:\")\n",
    "            example = data[0]\n",
    "            print(f\"  Image ID: {example[0]}\")\n",
    "            print(f\"  Correct caption: {example[1]}\")\n",
    "            if len(example) > 2:\n",
    "                print(f\"  Incorrect caption: {example[2]}\")\n",
    "            if len(example) > 3:\n",
    "                print(f\"  Additional fields: {example[3:]}\")\n",
    "    \n",
    "    # Extract correct captions to analyze prepositions\n",
    "    correct_captions = [get_correct_caption(item) for item in data]\n",
    "    \n",
    "    # Extract spatial relations (prepositions)\n",
    "    spatial_words = ['left', 'right', 'above', 'below', 'up', 'down', 'front', 'behind', 'on', 'under']\n",
    "    caption_relations = []\n",
    "    \n",
    "    for caption in correct_captions:\n",
    "        caption_lower = caption.lower()\n",
    "        for word in spatial_words:\n",
    "            if word in caption_lower:\n",
    "                caption_relations.append(word)\n",
    "                break\n",
    "    \n",
    "    if caption_relations:\n",
    "        relation_dist = Counter(caption_relations)\n",
    "        print(f\"\\nSpatial relation distribution:\")\n",
    "        for rel, count in relation_dist.most_common():\n",
    "            print(f\"  {rel}: {count} ({count/len(data)*100:.1f}%)\")\n",
    "    \n",
    "    # Show some example captions\n",
    "    print(f\"\\nExample correct captions:\")\n",
    "    for caption in correct_captions[:5]:\n",
    "        print(f\"  - {caption}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all datasets\n",
    "for dataset_key in DATASETS.keys():\n",
    "    try:\n",
    "        data, config = load_dataset(dataset_key)\n",
    "        analyze_dataset(data, dataset_key)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError loading {dataset_key}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_example(data, config, index, dataset_key):\n",
    "    \"\"\"Display a single example with image and captions\n",
    "    \n",
    "    Handles both list and dictionary formats\n",
    "    \"\"\"\n",
    "    example = data[index]\n",
    "    \n",
    "    # Extract data based on format\n",
    "    image_id = get_image_id(example)\n",
    "    correct_caption = get_correct_caption(example)\n",
    "    incorrect_captions = get_incorrect_captions(example)\n",
    "    \n",
    "    # Create figure with image and text\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Load and display image\n",
    "    img_path = get_image_path(config, image_id, dataset_key)\n",
    "    \n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f\"Image not found:\\n{img_path}\", \n",
    "                ha='center', va='center', fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Display captions as title with color coding\n",
    "    title_lines = [f\"✓ CORRECT: {correct_caption}\"]\n",
    "    for i, inc_cap in enumerate(incorrect_captions, 1):\n",
    "        title_lines.append(f\"✗ INCORRECT {i}: {inc_cap}\")\n",
    "    title = '\\n'.join(title_lines)\n",
    "    \n",
    "    plt.title(title, fontsize=11, pad=20, loc='left')\n",
    "    \n",
    "    # Print all metadata\n",
    "    print(f\"\\nExample {index + 1}/{len(data)}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"Image ID/Path: {image_id}\")\n",
    "    print(f\"Full image path: {img_path}\")\n",
    "    print(f\"\\n✓ CORRECT caption:\")\n",
    "    print(f\"  {correct_caption}\")\n",
    "    print(f\"\\n✗ INCORRECT caption(s):\")\n",
    "    for i, inc_cap in enumerate(incorrect_captions, 1):\n",
    "        print(f\"  {i}. {inc_cap}\")\n",
    "    \n",
    "    # Show raw data structure\n",
    "    if is_dict_format(example):\n",
    "        print(f\"\\nFormat: Dictionary with {len(example['caption_options'])} caption options\")\n",
    "    else:\n",
    "        print(f\"\\nFormat: List with {len(example)} elements\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive browser\n",
    "def create_browser(dataset_key):\n",
    "    \"\"\"Create an interactive browser for a dataset\"\"\"\n",
    "    data, config = load_dataset(dataset_key)\n",
    "    \n",
    "    # Widgets\n",
    "    index_slider = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(data)-1,\n",
    "        step=1,\n",
    "        description='Index:',\n",
    "        continuous_update=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    random_button = widgets.Button(description=\"Random Example\")\n",
    "    \n",
    "    # Filter by spatial relation\n",
    "    correct_captions = [get_correct_caption(item) for item in data]\n",
    "    spatial_words = ['left', 'right', 'above', 'below', 'up', 'down', 'front', 'behind', 'on', 'under']\n",
    "    relations_found = set()\n",
    "    for caption in correct_captions:\n",
    "        for word in spatial_words:\n",
    "            if word in caption.lower():\n",
    "                relations_found.add(word)\n",
    "    \n",
    "    filter_dropdown = widgets.Dropdown(\n",
    "        options=['all'] + sorted(list(relations_found)),\n",
    "        value='all',\n",
    "        description='Filter by:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Store filtered indices\n",
    "    filtered_indices = list(range(len(data)))\n",
    "    \n",
    "    def update_filtered_indices():\n",
    "        nonlocal filtered_indices\n",
    "        if filter_dropdown.value == 'all':\n",
    "            filtered_indices = list(range(len(data)))\n",
    "        else:\n",
    "            filtered_indices = [i for i, item in enumerate(data) \n",
    "                              if filter_dropdown.value in get_correct_caption(item).lower()]\n",
    "        index_slider.max = max(0, len(filtered_indices) - 1)\n",
    "        index_slider.value = 0\n",
    "    \n",
    "    def on_index_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            if filtered_indices:\n",
    "                actual_index = filtered_indices[change['new']]\n",
    "                display_example(data, config, actual_index, dataset_key)\n",
    "    \n",
    "    def on_random_click(b):\n",
    "        if filtered_indices:\n",
    "            index_slider.value = random.randint(0, len(filtered_indices)-1)\n",
    "    \n",
    "    def on_filter_change(change):\n",
    "        update_filtered_indices()\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            if filtered_indices:\n",
    "                display_example(data, config, filtered_indices[0], dataset_key)\n",
    "    \n",
    "    index_slider.observe(on_index_change, names='value')\n",
    "    random_button.on_click(on_random_click)\n",
    "    filter_dropdown.observe(on_filter_change, names='value')\n",
    "    \n",
    "    # Initial display\n",
    "    with output:\n",
    "        display_example(data, config, 0, dataset_key)\n",
    "    \n",
    "    controls = widgets.HBox([index_slider, filter_dropdown, random_button])\n",
    "    display(widgets.VBox([controls, output]))\n",
    "\n",
    "# Example: Browse a specific dataset\n",
    "print(\"Available datasets:\")\n",
    "for key, config in DATASETS.items():\n",
    "    print(f\"  - {key}: {config['description']}\")\n",
    "\n",
    "print(\"\\nUse: create_browser('dataset_key') to browse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse Visual Genome two objects\n",
    "create_browser('vg_two_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse COCO two objects\n",
    "create_browser('coco_two_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse Controlled images\n",
    "create_browser('controlled_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse Controlled CLEVR\n",
    "create_browser('controlled_clevr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Sample Grid Visualization\n\nDisplay a 3x3 grid of random samples from each dataset"
  },
  {
   "cell_type": "markdown",
   "source": "## Statistical Comparison Across Datasets",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Display 3x3 grid for a specific dataset\ndisplay_sample_grid('vg_two_obj', n_samples=9)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def display_sample_grid(dataset_key, n_samples=9, figsize=(15, 15)):\n    \"\"\"\n    Display a grid of random samples from a dataset\n    \n    Args:\n        dataset_key: Which dataset to display\n        n_samples: Number of samples to show (default: 9 for 3x3 grid)\n        figsize: Figure size tuple\n    \"\"\"\n    data, config = load_dataset(dataset_key)\n    \n    # Calculate grid dimensions\n    grid_size = int(n_samples ** 0.5)\n    if grid_size * grid_size < n_samples:\n        grid_size += 1\n    \n    # Sample random indices\n    sample_indices = random.sample(range(len(data)), min(n_samples, len(data)))\n    \n    # Create figure\n    fig, axes = plt.subplots(grid_size, grid_size, figsize=figsize)\n    axes = axes.flatten() if n_samples > 1 else [axes]\n    \n    for idx, sample_idx in enumerate(sample_indices):\n        ax = axes[idx]\n        example = data[sample_idx]\n        \n        # Extract data based on format\n        image_id = get_image_id(example)\n        correct_caption = get_correct_caption(example)\n        \n        # Load and display image\n        img_path = get_image_path(config, image_id, dataset_key)\n        \n        if img_path.exists():\n            img = Image.open(img_path)\n            ax.imshow(img)\n        else:\n            ax.text(0.5, 0.5, \"Image\\nnot found\", \n                    ha='center', va='center', fontsize=8)\n        \n        ax.axis('off')\n        \n        # Add caption as title (wrap long captions)\n        caption = correct_caption\n        if len(caption) > 60:\n            caption = caption[:57] + \"...\"\n        ax.set_title(caption, fontsize=8, pad=5, wrap=True)\n    \n    # Hide unused subplots\n    for idx in range(len(sample_indices), len(axes)):\n        axes[idx].axis('off')\n    \n    plt.suptitle(f\"{DATASETS[dataset_key]['description']}\\n({len(data)} total samples)\", \n                 fontsize=12, fontweight='bold', y=0.98)\n    plt.tight_layout()\n    plt.show()\n\n\ndef display_all_dataset_grids(n_samples=9, figsize=(15, 15)):\n    \"\"\"Display sample grids for all datasets\"\"\"\n    for dataset_key in DATASETS.keys():\n        try:\n            print(f\"\\n{'='*80}\")\n            print(f\"Dataset: {dataset_key}\")\n            print(f\"{'='*80}\")\n            display_sample_grid(dataset_key, n_samples=n_samples, figsize=figsize)\n        except Exception as e:\n            print(f\"Error displaying {dataset_key}: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets():\n",
    "    \"\"\"Compare statistics across all datasets\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (dataset_key, config) in enumerate(DATASETS.items()):\n",
    "        try:\n",
    "            data, _ = load_dataset(dataset_key)\n",
    "            \n",
    "            # Extract spatial relations from correct captions\n",
    "            correct_captions = [get_correct_caption(item) for item in data]\n",
    "            spatial_words = ['left', 'right', 'above', 'below', 'up', 'down', 'front', 'behind', 'on', 'under']\n",
    "            caption_relations = []\n",
    "            \n",
    "            for caption in correct_captions:\n",
    "                caption_lower = caption.lower()\n",
    "                for word in spatial_words:\n",
    "                    if word in caption_lower:\n",
    "                        caption_relations.append(word)\n",
    "                        break\n",
    "            \n",
    "            if caption_relations:\n",
    "                relation_dist = Counter(caption_relations)\n",
    "                labels = list(relation_dist.keys())\n",
    "                values = list(relation_dist.values())\n",
    "                \n",
    "                axes[idx].bar(labels, values, color='steelblue')\n",
    "                axes[idx].set_title(f\"{dataset_key}\\n({len(data)} samples)\", fontsize=11, fontweight='bold')\n",
    "                axes[idx].set_ylabel('Count', fontsize=10)\n",
    "                axes[idx].tick_params(axis='x', rotation=45, labelsize=9)\n",
    "                axes[idx].grid(axis='y', alpha=0.3)\n",
    "        except Exception as e:\n",
    "            axes[idx].text(0.5, 0.5, f\"Error: {str(e)[:50]}\", \n",
    "                          ha='center', va='center', transform=axes[idx].transAxes,\n",
    "                          fontsize=9, wrap=True)\n",
    "            axes[idx].set_title(f\"{dataset_key}\\n(Error)\", fontsize=11)\n",
    "    \n",
    "    plt.suptitle('Spatial Relation Distribution Across Datasets', fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_examples(dataset_key, spatial_relation=None, caption_contains=None):\n",
    "    \"\"\"Search for specific examples\n",
    "    \n",
    "    Args:\n",
    "        dataset_key: Which dataset to search\n",
    "        spatial_relation: Filter by spatial relation (e.g., 'left', 'right', 'above')\n",
    "        caption_contains: Filter by text in correct caption\n",
    "    \"\"\"\n",
    "    data, config = load_dataset(dataset_key)\n",
    "    \n",
    "    filtered = data\n",
    "    \n",
    "    if spatial_relation:\n",
    "        filtered = [item for item in filtered \n",
    "                   if spatial_relation.lower() in get_correct_caption(item).lower()]\n",
    "    \n",
    "    if caption_contains:\n",
    "        filtered = [item for item in filtered \n",
    "                   if caption_contains.lower() in get_correct_caption(item).lower()]\n",
    "    \n",
    "    print(f\"Found {len(filtered)} examples matching criteria\")\n",
    "    \n",
    "    # Show first few examples\n",
    "    if filtered:\n",
    "        print(\"\\nFirst 5 matches:\")\n",
    "        for i, item in enumerate(filtered[:5]):\n",
    "            print(f\"\\n{i+1}. Image: {get_image_id(item)}\")\n",
    "            print(f\"   Correct: {get_correct_caption(item)}\")\n",
    "            incorrect = get_incorrect_captions(item)\n",
    "            if incorrect:\n",
    "                print(f\"   Incorrect: {incorrect[0] if len(incorrect) == 1 else incorrect}\")\n",
    "    \n",
    "    return filtered, config\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# filtered_data, config = search_examples('coco_two_obj', spatial_relation='left')\n",
    "# if filtered_data:\n",
    "#     display_example(filtered_data, config, 0, 'coco_two_obj')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}